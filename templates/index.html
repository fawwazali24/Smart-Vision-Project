<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Camera with ML Prediction</title>
  <style>
    body {
      display: flex;
      justify-content: center;
      align-items: center;
      height: 100vh;
      margin: 0;
      flex-direction: column;
    }
    #camera-box {
      width: 480px;
      height: 480px;
      border: 2px solid black;
      overflow: hidden;
      display: flex;
      justify-content: center;
      align-items: center;
      position: relative;
    }
    video {
      width: 100%;
      height: 100%;
      object-fit: cover;
      transform: scaleX(1); /* Start without mirroring for back camera */
    }
    #prediction-box {
      margin-top: 10px;
      text-align: center;
    }
    #switch-camera {
      margin-top: 20px;
    }
  </style>
</head>
<body>
  <h1>Camera with ML Prediction</h1>
  <div id="camera-box">
    <video id="video" autoplay></video>
  </div>
  <div id="prediction-box">
    <p id="prediction">Prediction: <span id="prediction-text">N/A</span></p>
    <p id="Text Present">Text Present: <span id="prediction-text2">N/A</span></p>
  </div>
  <button id="switch-camera">Switch Camera</button>

  <script>
    const video = document.getElementById('video');
    const predictionElem = document.getElementById('prediction-text');
    const predictionElem2 = document.getElementById('prediction-text2');
    const switchCameraBtn = document.getElementById('switch-camera');
    let useFrontCamera = false; // Start with front-facing camera

    // Function to start the camera stream
    function startCamera() {
      navigator.mediaDevices.getUserMedia({
        video: {
          facingMode: useFrontCamera ? 'user' : 'environment' // 'user' for front-facing, 'environment' for back camera
        }
      })
      .then(stream => {
        video.srcObject = stream;
        // Flip the video if using the front-facing camera
        video.style.transform = useFrontCamera ? 'scaleX(-1)' : 'scaleX(1)';
      })
      .catch(err => {
        console.error("Error accessing the camera:", err);
      });
    }

    // Start the camera with the back camera by default
    startCamera();

    // Switch camera button event listener
    switchCameraBtn.addEventListener('click', () => {
      useFrontCamera = !useFrontCamera; // Toggle camera mode
      startCamera(); // Restart camera with the new mode
    });

    // Function to capture and send image every second
    setInterval(() => {
      const canvas = document.createElement('canvas');
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      const context = canvas.getContext('2d');
      context.drawImage(video, 0, 0, canvas.width, canvas.height);
      
      // Convert the image to base64
      const imageData = canvas.toDataURL('image/jpeg');

      // Perform OCR first to check if text is present
      fetch('/ocr', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({ image: imageData }),
      })
      .then(response => response.json())
      .then(data => {
        const isTextPresent = data.text_present;
        predictionElem2.textContent = `: ${isTextPresent}`;

        // Based on OCR result, decide whether to perform vegetable prediction or YOLO detection
        if (isTextPresent) {
          // Perform YOLO detection for text
          fetch('/detect', {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
            },
            body: JSON.stringify({ image: imageData }),
          })
          .then(response => response.json())
          .then(data => {
            predictionElem.textContent = `Packaged: ${data.predictions.join(', ')}`; // Update YOLO predictions
          })
          .catch(err => console.error('Error:', err));
        } else {
          // Perform vegetable prediction if no text is detected
          fetch('/predict', {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
            },
            body: JSON.stringify({ image: imageData }),
          })
          .then(response => response.json())
          .then(data => {
            predictionElem.textContent = `Vegetable: ${data.predictions.join(', ')}`; // Update vegetable prediction
          })
          .catch(err => console.error('Error:', err));
        }
      })
      .catch(err => console.error('Error:', err));
    }, 1000); // Capture every 1000 milliseconds (1 second)

  </script>
</body>
</html>